{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50092251",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "network.py\n",
    "~~~~~~~~~~\n",
    "\n",
    "A module to implement the stochastic gradient descent learning\n",
    "algorithm for a feedforward neural network.  Gradients are calculated\n",
    "using backpropagation.  Note that I have focused on making the code\n",
    "simple, easily readable, and easily modifiable.  It is not optimized,\n",
    "and omits many desirable features.\n",
    "\"\"\"\n",
    "\n",
    "#### Libraries\n",
    "# Standard library\n",
    "import random\n",
    "import pickle  # Add this for saving/loading\n",
    "\n",
    "# Third-party libraries\n",
    "import numpy as np\n",
    "\n",
    "class Network(object):\n",
    "\n",
    "    def __init__(self, sizes):\n",
    "        \"\"\"The list ``sizes`` contains the number of neurons in the\n",
    "        respective layers of the network.  For example, if the list\n",
    "        was [2, 3, 1] then it would be a three-layer network, with the\n",
    "        first layer containing 2 neurons, the second layer 3 neurons,\n",
    "        and the third layer 1 neuron.  The biases and weights for the\n",
    "        network are initialized randomly, using a Gaussian\n",
    "        distribution with mean 0, and variance 1.  Note that the first\n",
    "        layer is assumed to be an input layer, and by convention we\n",
    "        won't set any biases for those neurons, since biases are only\n",
    "        ever used in computing the outputs from later layers.\"\"\"\n",
    "        self.num_layers = len(sizes)\n",
    "        self.sizes = sizes\n",
    "        self.biases = [np.random.randn(y, 1) for y in sizes[1:]]\n",
    "        self.weights = [np.random.randn(y, x)\n",
    "                        for x, y in zip(sizes[:-1], sizes[1:])]\n",
    "\n",
    "    def feedforward(self, a):\n",
    "        \"\"\"Return the output of the network if ``a`` is input.\"\"\"\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            a = sigmoid(np.dot(w, a)+b)\n",
    "        return a\n",
    "\n",
    "    def SGD(self, training_data, epochs, mini_batch_size, eta,\n",
    "            test_data=None):\n",
    "        \"\"\"Train the neural network using mini-batch stochastic\n",
    "        gradient descent.  The ``training_data`` is a list of tuples\n",
    "        ``(x, y)`` representing the training inputs and the desired\n",
    "        outputs.  The other non-optional parameters are\n",
    "        self-explanatory.  If ``test_data`` is provided then the\n",
    "        network will be evaluated against the test data after each\n",
    "        epoch, and partial progress printed out.  This is useful for\n",
    "        tracking progress, but slows things down substantially.\"\"\"\n",
    "        if test_data: n_test = len(test_data)\n",
    "        n = len(training_data)\n",
    "        for j in range(epochs):\n",
    "            random.shuffle(training_data)\n",
    "            mini_batches = [\n",
    "                training_data[k:k+mini_batch_size]\n",
    "                for k in range(0, n, mini_batch_size)]\n",
    "            for mini_batch in mini_batches:\n",
    "                self.update_mini_batch(mini_batch, eta)\n",
    "            if test_data:\n",
    "                print(\"Epoch {0}: {1} / {2}\".format(\n",
    "                    j, self.evaluate(test_data), n_test))\n",
    "            else:\n",
    "                print(\"Epoch {0} complete\".format(j))\n",
    "\n",
    "    def update_mini_batch(self, mini_batch, eta):\n",
    "        \"\"\"Update the network's weights and biases by applying\n",
    "        gradient descent using backpropagation to a single mini batch.\n",
    "        The ``mini_batch`` is a list of tuples ``(x, y)``, and ``eta``\n",
    "        is the learning rate.\"\"\"\n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        for x, y in mini_batch:\n",
    "            delta_nabla_b, delta_nabla_w = self.backprop(x, y)\n",
    "            nabla_b = [nb+dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]\n",
    "            nabla_w = [nw+dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]\n",
    "        self.weights = [w-(eta/len(mini_batch))*nw\n",
    "                        for w, nw in zip(self.weights, nabla_w)]\n",
    "        self.biases = [b-(eta/len(mini_batch))*nb\n",
    "                       for b, nb in zip(self.biases, nabla_b)]\n",
    "\n",
    "    def backprop(self, x, y):\n",
    "        \"\"\"Return a tuple ``(nabla_b, nabla_w)`` representing the\n",
    "        gradient for the cost function C_x.  ``nabla_b`` and\n",
    "        ``nabla_w`` are layer-by-layer lists of numpy arrays, similar\n",
    "        to ``self.biases`` and ``self.weights``.\"\"\"\n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        # feedforward\n",
    "        activation = x\n",
    "        activations = [x] # list to store all the activations, layer by layer\n",
    "        zs = [] # list to store all the z vectors, layer by layer\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            z = np.dot(w, activation)+b\n",
    "            zs.append(z)\n",
    "            activation = sigmoid(z)\n",
    "            activations.append(activation)\n",
    "        # backward pass\n",
    "        delta = self.cost_derivative(activations[-1], y) * \\\n",
    "            sigmoid_prime(zs[-1])\n",
    "        nabla_b[-1] = delta\n",
    "        nabla_w[-1] = np.dot(delta, activations[-2].transpose())\n",
    "        # Note that the variable l in the loop below is used a little\n",
    "        # differently to the notation in Chapter 2 of the book.  Here,\n",
    "        # l = 1 means the last layer of neurons, l = 2 is the\n",
    "        # second-last layer, and so on.  It's a renumbering of the\n",
    "        # scheme in the book, used here to take advantage of the fact\n",
    "        # that Python can use negative indices in lists.\n",
    "        for l in range(2, self.num_layers):\n",
    "            z = zs[-l]\n",
    "            sp = sigmoid_prime(z)\n",
    "            delta = np.dot(self.weights[-l+1].transpose(), delta) * sp\n",
    "            nabla_b[-l] = delta\n",
    "            nabla_w[-l] = np.dot(delta, activations[-l-1].transpose())\n",
    "        return (nabla_b, nabla_w)\n",
    "\n",
    "    def evaluate(self, test_data):\n",
    "        \"\"\"Return the number of test inputs for which the neural\n",
    "        network outputs the correct result. Note that the neural\n",
    "        network's output is assumed to be the index of whichever\n",
    "        neuron in the final layer has the highest activation.\"\"\"\n",
    "        test_results = [(np.argmax(self.feedforward(x)), y)\n",
    "                        for (x, y) in test_data]\n",
    "        return sum(int(x == y) for (x, y) in test_results)\n",
    "\n",
    "    def cost_derivative(self, output_activations, y):\n",
    "        r\"\"\"Return the vector of partial derivatives \\partial C_x /\n",
    "        \\partial a for the output activations.\"\"\"\n",
    "        return (output_activations-y)\n",
    "        \n",
    "    def save(self, filename):\n",
    "        \"\"\"Save weights and biases to a file.\"\"\"\n",
    "        data = {\"sizes\": self.sizes,\n",
    "                \"weights\": [w.tolist() for w in self.weights],\n",
    "                \"biases\": [b.tolist() for b in self.biases]}\n",
    "        with open(filename, \"wb\") as f:\n",
    "            pickle.dump(data, f)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, filename):\n",
    "        \"\"\"Load weights and biases from a file.\"\"\"\n",
    "        with open(filename, \"rb\") as f:\n",
    "            data = pickle.load(f)\n",
    "        net = cls(data[\"sizes\"])\n",
    "        net.weights = [np.array(w) for w in data[\"weights\"]]\n",
    "        net.biases = [np.array(b) for b in data[\"biases\"]]\n",
    "        return net\n",
    "\n",
    "#### Miscellaneous functions\n",
    "def sigmoid(z):\n",
    "    \"\"\"The sigmoid function.\"\"\"\n",
    "    return 1.0/(1.0+np.exp(-z))\n",
    "\n",
    "def sigmoid_prime(z):\n",
    "    \"\"\"Derivative of the sigmoid function.\"\"\"\n",
    "    return sigmoid(z)*(1-sigmoid(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff74bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 50000 examples\n",
      "Validation data: 10000 examples\n",
      "Test data: 10000 examples\n",
      "Input size: (784, 1)\n",
      "Output size: (10, 1)\n",
      "Creating a neural network with 100 hidden neurons...\n",
      "Training the network...\n",
      "This will take a few minutes. You should see progress after each epoch.\n",
      "\n",
      "Epoch 0: 8201 / 10000\n",
      "Epoch 1: 8356 / 10000\n",
      "Epoch 2: 8419 / 10000\n",
      "Epoch 3: 8481 / 10000\n",
      "Epoch 4: 8518 / 10000\n",
      "Epoch 5: 8527 / 10000\n",
      "Epoch 6: 8568 / 10000\n",
      "Epoch 7: 8578 / 10000\n",
      "Epoch 8: 8585 / 10000\n",
      "Epoch 9: 9447 / 10000\n",
      "Epoch 10: 9464 / 10000\n",
      "Epoch 11: 9440 / 10000\n",
      "Epoch 12: 9451 / 10000\n",
      "Epoch 13: 9478 / 10000\n",
      "Epoch 14: 9465 / 10000\n",
      "Epoch 15: 9472 / 10000\n",
      "Epoch 16: 9496 / 10000\n",
      "Epoch 17: 9496 / 10000\n",
      "Epoch 18: 9495 / 10000\n",
      "Epoch 19: 9489 / 10000\n",
      "Epoch 20: 9491 / 10000\n",
      "Epoch 21: 9499 / 10000\n",
      "Epoch 22: 9518 / 10000\n",
      "Epoch 23: 9513 / 10000\n",
      "Epoch 24: 9509 / 10000\n",
      "Epoch 25: 9508 / 10000\n",
      "Epoch 26: 9495 / 10000\n",
      "Epoch 27: 9481 / 10000\n",
      "Epoch 28: 9475 / 10000\n",
      "Epoch 29: 9496 / 10000\n",
      "Trained model saved to 'trained_digit_net.pkl'\n"
     ]
    }
   ],
   "source": [
    "# Load the MNIST data\n",
    "import mnist_loader\n",
    "training_data, validation_data, test_data = mnist_loader.load_data_wrapper()\n",
    "\n",
    "print(f\"Training data: {len(training_data)} examples\")\n",
    "print(f\"Validation data: {len(validation_data)} examples\") \n",
    "print(f\"Test data: {len(test_data)} examples\")\n",
    "print(f\"Input size: {training_data[0][0].shape}\")\n",
    "print(f\"Output size: {training_data[0][1].shape}\")\n",
    "\n",
    "# Create and train a neural network with 30 hidden neurons\n",
    "print(\"Creating a neural network with 30 hidden neurons...\")\n",
    "net = Network([784, 30, 10])\n",
    "\n",
    "print(\"Training the network...\")\n",
    "print(\"This will take a few minutes. You should see progress after each epoch.\")\n",
    "print()\n",
    "\n",
    "# Train for 30 epochs with mini-batch size 10 and learning rate 3.0\n",
    "net.SGD(training_data, 30, 10, 3.0, test_data=test_data)\n",
    "\n",
    "# Save the trained model to a file\n",
    "net.save(\"trained_digit_net.pkl\")\n",
    "print(\"Trained model saved to 'trained_digit_net.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "242fe6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model accuracy: 9496 / 10000 (94.96%)\n",
      "Predicted: 7, Expected: 7\n"
     ]
    }
   ],
   "source": [
    "# Test loading the saved model\n",
    "loaded_net = Network.load(\"trained_digit_net.pkl\")\n",
    "\n",
    "# Evaluate on test data to confirm it matches the trained accuracy\n",
    "accuracy = loaded_net.evaluate(test_data)\n",
    "print(f\"Loaded model accuracy: {accuracy} / {len(test_data)} ({accuracy / len(test_data) * 100:.2f}%)\")\n",
    "\n",
    "# Optional: Test a single prediction (e.g., first test image)\n",
    "test_input, expected_label = test_data[0]\n",
    "output = loaded_net.feedforward(test_input)\n",
    "predicted_label = np.argmax(output)\n",
    "print(f\"Predicted: {predicted_label}, Expected: {expected_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68d57b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded trained model from 'trained_digit_net.pkl'\n",
      "\n",
      "Testing individual predictions:\n",
      "========================================\n",
      "Example 1: True digit = 6, Predicted digit = 6\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 2: True digit = 7, Predicted digit = 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 3: True digit = 0, Predicted digit = 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the MNIST data\n",
    "import mnist_loader\n",
    "training_data, validation_data, test_data = mnist_loader.load_data_wrapper()\n",
    "\n",
    "# Import necessary modules\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming the Network class is already defined in a previous cell in this notebook,\n",
    "# no need to import it from a separate file. If it's not defined yet, paste the full\n",
    "# Network class code (including save/load methods) into a cell above this one and run it.\n",
    "\n",
    "# Load the trained model\n",
    "loaded_net = Network.load(\"trained_digit_net.pkl\")\n",
    "print(\"Loaded trained model from 'trained_digit_net.pkl'\")\n",
    "\n",
    "def test_individual_predictions(network, test_data, num_examples=5):\n",
    "    \"\"\"Test the network on a few individual examples and show the images\"\"\"\n",
    "    print(\"\\nTesting individual predictions:\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    # Take a few random examples\n",
    "    indices = np.random.choice(len(test_data), num_examples, replace=False)\n",
    "    \n",
    "    for i, idx in enumerate(indices):\n",
    "        x, y = test_data[idx]\n",
    "        prediction = np.argmax(network.feedforward(x))\n",
    "        \n",
    "        print(f\"Example {i+1}: True digit = {y}, Predicted digit = {prediction}\")\n",
    "        \n",
    "        # Display the image\n",
    "        plt.figure(figsize=(3, 3))\n",
    "        image = x.reshape(28, 28)\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        plt.title(f\"True: {y}, Predicted: {prediction}\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "# Test the loaded network\n",
    "test_individual_predictions(loaded_net, test_data, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0092fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "\n",
    "# Load pkl\n",
    "with open('trained_digit_net.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# Convert to JSON-friendly (already lists, so no tolist needed)\n",
    "json_data = {\n",
    "    \"sizes\": data[\"sizes\"],\n",
    "    \"weights\": data[\"weights\"],\n",
    "    \"biases\": data[\"biases\"]\n",
    "}\n",
    "\n",
    "# Save JSON\n",
    "with open('trained_digit_net.json', 'w') as f:\n",
    "    json.dump(json_data, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
